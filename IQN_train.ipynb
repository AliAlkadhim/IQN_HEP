{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40Yb47zJQglm"
   },
   "source": [
    "## Implicit Quantile Networks for Event Folding\n",
    "Created: June 13, 2022 Ali & Harrison<br>\n",
    "\n",
    "### Introduction \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FA1Y5VCv20XZ"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# the standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# the standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# the standard modules for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard scientific python module\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.optimize as op\n",
    "\n",
    "# standard symbolic algebra module\n",
    "import sympy as sm\n",
    "sm.init_printing()\n",
    "\n",
    "# module to save results\n",
    "import joblib as jb\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# split data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# linearly transform a feature to zero mean and unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to reload modules\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update fonts\n",
    "FONTSIZE = 18\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "\n",
    "# set usetex = False if LaTex is not \n",
    "# available on your system or if the \n",
    "# rendering is too slow\n",
    "mp.rc('text', usetex=True)\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "#seed = 128\n",
    "#rnd  = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 100000\n",
      "\n",
      "Columns: ['rawRecoDatapT', 'rawRecoDataeta', 'rawRecoDataphi', 'rawRecoDatam', 'RecoDatapT', 'RecoDataeta', 'RecoDataphi', 'RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Fields: ['RecoDatapT', 'RecoDataeta', 'RecoDataphi', 'RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target: RecoDatapT\n",
      "\n",
      "Features: ['RecoDataeta', 'RecoDataphi', 'RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecoDatapT</th>\n",
       "      <th>RecoDataeta</th>\n",
       "      <th>RecoDataphi</th>\n",
       "      <th>RecoDatam</th>\n",
       "      <th>genDatapT</th>\n",
       "      <th>genDataeta</th>\n",
       "      <th>genDataphi</th>\n",
       "      <th>genDatam</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>45.4608</td>\n",
       "      <td>3.379820</td>\n",
       "      <td>1.470130</td>\n",
       "      <td>13.24440</td>\n",
       "      <td>0.536525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>56.2643</td>\n",
       "      <td>0.811412</td>\n",
       "      <td>-1.324120</td>\n",
       "      <td>10.55060</td>\n",
       "      <td>0.130536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.3586</td>\n",
       "      <td>-1.17862</td>\n",
       "      <td>1.84039</td>\n",
       "      <td>9.95503</td>\n",
       "      <td>34.6377</td>\n",
       "      <td>-1.131020</td>\n",
       "      <td>1.801820</td>\n",
       "      <td>7.65844</td>\n",
       "      <td>0.500162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.9593</td>\n",
       "      <td>2.13374</td>\n",
       "      <td>-2.86886</td>\n",
       "      <td>9.55921</td>\n",
       "      <td>27.4120</td>\n",
       "      <td>-2.842550</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>5.18675</td>\n",
       "      <td>0.490624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.2909</td>\n",
       "      <td>2.96499</td>\n",
       "      <td>1.36464</td>\n",
       "      <td>10.69580</td>\n",
       "      <td>30.3263</td>\n",
       "      <td>3.040300</td>\n",
       "      <td>1.341270</td>\n",
       "      <td>5.74890</td>\n",
       "      <td>0.417064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecoDatapT  RecoDataeta  RecoDataphi  RecoDatam  genDatapT  genDataeta  \\\n",
       "0     40.3892      3.41479      1.47023   12.53740    45.4608    3.379820   \n",
       "1     40.3892      3.41479      1.47023   12.53740    56.2643    0.811412   \n",
       "2     29.3586     -1.17862      1.84039    9.95503    34.6377   -1.131020   \n",
       "3     20.9593      2.13374     -2.86886    9.55921    27.4120   -2.842550   \n",
       "4     35.2909      2.96499      1.36464   10.69580    30.3263    3.040300   \n",
       "\n",
       "   genDataphi  genDatam       tau  \n",
       "0    1.470130  13.24440  0.536525  \n",
       "1   -1.324120  10.55060  0.130536  \n",
       "2    1.801820   7.65844  0.500162  \n",
       "3    0.345529   5.18675  0.490624  \n",
       "4    1.341270   5.74890  0.417064  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data    = pd.read_csv('Data.csv')\n",
    "print('number of entries:', len(data))\n",
    "\n",
    "columns = list(data.columns)[1:]\n",
    "print('\\nColumns:', columns)\n",
    "\n",
    "fields  = list(data.columns)[5:]\n",
    "print('\\nFields:', fields)\n",
    "\n",
    "target  = 'RecoDatapT'\n",
    "print('\\nTarget:', target )\n",
    "\n",
    "features= [x for x in fields]\n",
    "features.remove(target)\n",
    "\n",
    "print('\\nFeatures:', features)\n",
    "\n",
    "data    = data[fields]\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validation, and test sets\n",
    "There is some confusion in terminology regarding validation and test samples (or sets). We shall adhere to the defintions given here https://machinelearningmastery.com/difference-test-validation-datasets/):\n",
    "   \n",
    "  * __Training Dataset__: The sample of data used to fit the model.\n",
    "  * __Validation Dataset__: The sample of data used to decide 1) whether the fit is reasonable (e.g., the model has not been overfitted), 2) decide which of several models is the best and 3) tune model hyperparameters.\n",
    "  * __Test Dataset__: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "The validation set will be some small fraction of the training set and can be used, for example, to decide when to stop the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size:         75000\n",
      "validation set size:     5000\n",
      "test set size:          20000\n"
     ]
    }
   ],
   "source": [
    "# Fraction of the data assigned as test data\n",
    "fraction = 20/100\n",
    "# Split data into a part for training and a part for testing\n",
    "train_data, test_data = train_test_split(data, \n",
    "                                         test_size=fraction)\n",
    "\n",
    "# Split the training data into a part for training (fitting) and\n",
    "# a part for validating the training.\n",
    "fraction = 5/80\n",
    "train_data, valid_data = train_test_split(train_data, \n",
    "                                          test_size=fraction)\n",
    "\n",
    "# reset the indices in the dataframes and drop the old ones\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "valid_data = valid_data.reset_index(drop=True)\n",
    "test_data  = test_data.reset_index(drop=True)\n",
    "\n",
    "print('train set size:        %6d' % train_data.shape[0])\n",
    "print('validation set size:   %6d' % valid_data.shape[0])\n",
    "print('test set size:         %6d' % test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into targets $t$ and inputs $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle \\left( \\left( 75000,\\right), \\  \\left( 75000, \\  8\\right)\\right)$"
      ],
      "text/plain": [
       "((75000,), (75000, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_t_x(df, target, source, scalers):\n",
    "    # change from pandas dataframe format to a numpy array\n",
    "    scaler_t, scaler_x = scalers\n",
    "    t = np.array(scaler_t.transform(df[target].to_numpy().reshape(-1, 1)))\n",
    "    x = np.array(scaler_x.transform(df[source]))\n",
    "    t = t.reshape(-1,)\n",
    "    return t, x\n",
    "\n",
    "# create a scaler for target\n",
    "scaler_t = StandardScaler()\n",
    "scaler_t.fit(train_data[target].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# create a scaler for inputs\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(train_data[features])\n",
    "# NB: undo scaling of tau, which is the last feature\n",
    "scaler_x.mean_[-1] = 0\n",
    "scaler_x.scale_[-1]= 1\n",
    "\n",
    "scalers = [scaler_t, scaler_x]\n",
    "\n",
    "train_t, train_x = split_t_x(train_data, target, features, scalers)\n",
    "valid_t, valid_x = split_t_x(valid_data, target, features, scalers)\n",
    "test_t,  test_x  = split_t_x(test_data,  target, features, scalers)\n",
    "\n",
    "train_t.shape, train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile regression\n",
    "\n",
    "The empirical risk, which is the __objective function__ we shall minimize, is defined as\n",
    "\n",
    "\\begin{align}\n",
    "R_M(\\theta) & = \\frac{1}{M}\\sum_{m=1}^M L(t_m, f_m),\\\\\n",
    "\\text{where } f_m & \\equiv f(\\mathbf{x}_m, \\theta) .\n",
    "\\end{align}\n",
    "\n",
    "We shall use the __quantile loss__ defined by\n",
    "\n",
    "\\begin{align}\n",
    "L(t, f) & = \\begin{cases}\n",
    "    \\tau (t - f), & \\text{if } t \\geq f \\\\\n",
    "    (1 - \\tau)(f - t)              & \\text{otherwise} .\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "To show that this loss function indeed leads to $\\tau$-quantiles, consider the minimization of the __risk functional__\n",
    "\n",
    "\\begin{align}\n",
    "R[f] & = \\int \\int \\, p(t, \\mathbf{x}) \\, L(t, f(\\mathbf{x}, \\theta)) \\, dt \\, d\\mathbf{x}, \\\\\n",
    "\\frac{\\delta R}{\\delta f}  & = 0 .\n",
    "\\end{align}\n",
    "\n",
    "If the above is to hold $\\forall\\,\\,\\mathbf{x}$, then \n",
    "\n",
    "\\begin{align}\n",
    "\\int \\frac{\\partial L}{\\partial f} p(t | \\mathbf{x}) \\, dt & = 0,\\\\\n",
    "-\\tau \\int_{t \\ge f} p(t | \\mathbf{x}) \\, dt + (1 - \\tau)\\int_{t < f} p(t | \\mathbf{x}) \\, dt & = 0, \\\\\n",
    "\\therefore \\quad\\int_{t < f} p(t | \\mathbf{x}) \\, dt & = \\tau.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save training utilities to file SIR_dnn_util.py \n",
    "\n",
    "  1. get_batch\n",
    "  1. average_quadratic_loss\n",
    "  1. average_cross_entropy_loss\n",
    "  1. average_quantile_loss\n",
    "  1. validate\n",
    "  1. ModelHandler\n",
    "  1. train\n",
    "  1. plot_average_loss\n",
    "  1. hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting iqnutil.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iqnutil.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# the standard modules for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# return a batch of data for the next step in minimization\n",
    "def get_batch(x, t, batch_size):\n",
    "    # the numpy function choice(length, number)\n",
    "    # selects at random \"batch_size\" integers from \n",
    "    # the range [0, length-1] corresponding to the\n",
    "    # row indices.\n",
    "    rows    = np.random.choice(len(x), batch_size)\n",
    "    batch_x = x[rows]\n",
    "    batch_t = t[rows]\n",
    "    return (batch_x, batch_t)\n",
    "\n",
    "# Note: there are several average loss functions available \n",
    "# in pytorch, but it's useful to know how to create your own.\n",
    "def average_quadratic_loss(f, t, x):\n",
    "    # f and t must be of the same shape\n",
    "    return  torch.mean((f - t)**2)\n",
    "\n",
    "def average_cross_entropy_loss(f, t, x):\n",
    "    # f and t must be of the same shape\n",
    "    loss = torch.where(t > 0.5, torch.log(f), torch.log(1 - f))\n",
    "    return -torch.mean(loss)\n",
    "\n",
    "def average_quantile_loss(f, t, x):\n",
    "    # f and t must be of the same shape\n",
    "    tau = x.T[-1] # last column is tau.\n",
    "    return torch.mean(torch.where(t >= f, \n",
    "                                  tau * (t - f), \n",
    "                                  (1 - tau)*(f - t)))\n",
    "\n",
    "# function to validate model during training.\n",
    "def validate(model, avloss, inputs, targets):\n",
    "    # make sure we set evaluation mode so that any training specific\n",
    "    # operations are disabled.\n",
    "    model.eval() # evaluation mode\n",
    "    \n",
    "    with torch.no_grad(): # no need to compute gradients wrt. x and t\n",
    "        x = torch.from_numpy(inputs).float()\n",
    "        t = torch.from_numpy(targets).float()\n",
    "        # remember to reshape!\n",
    "        o = model(x).reshape(t.shape)\n",
    "    return avloss(o, t, x)\n",
    "\n",
    "# A simple wrapper around a model to make using the latter more\n",
    "# convenient\n",
    "class ModelHandler:\n",
    "    def __init__(self, model, scalers):\n",
    "        self.model  = model\n",
    "        self.scaler_t, self.scaler_x = scalers\n",
    "        \n",
    "        self.scale  = self.scaler_t.scale_[0] # for output\n",
    "        self.mean   = self.scaler_t.mean_[0]  # for output\n",
    "        self.fields = self.scaler_x.feature_names_in_\n",
    "        \n",
    "    def __call__(self, df):\n",
    "        \n",
    "        # scale input data\n",
    "        x  = np.array(self.scaler_x.transform(df[self.fields]))\n",
    "        x  = torch.Tensor(x)\n",
    "\n",
    "        # go to evaluation mode\n",
    "        self.model.eval()\n",
    "    \n",
    "        # compute,reshape to a 1d array, and convert to a numpy array\n",
    "        Y  = self.model(x).view(-1, ).detach().numpy()\n",
    "        \n",
    "        # rescale output\n",
    "        Y  = self.mean + self.scale * Y\n",
    "        \n",
    "        if len(Y) == 1:\n",
    "            return Y[0]\n",
    "        else:\n",
    "            return Y\n",
    "        \n",
    "    def show(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "                print()\n",
    "        \n",
    "def train(model, optimizer, avloss, getbatch,\n",
    "          train_x, train_t, \n",
    "          valid_x, valid_t,\n",
    "          batch_size, \n",
    "          n_iterations, traces, \n",
    "          step=50):\n",
    "    \n",
    "    # to keep track of average losses\n",
    "    xx, yy_t, yy_v = traces\n",
    "    \n",
    "    n = len(valid_x)\n",
    "    \n",
    "    print('Iteration vs average loss')\n",
    "    print(\"%10s\\t%10s\\t%10s\" % \\\n",
    "          ('iteration', 'train-set', 'valid-set'))\n",
    "    \n",
    "    for ii in range(n_iterations):\n",
    "\n",
    "        # set mode to training so that training specific \n",
    "        # operations such as dropout are enabled.\n",
    "        model.train()\n",
    "        \n",
    "        # get a random sample (a batch) of data (as numpy arrays)\n",
    "        batch_x, batch_t = getbatch(train_x, train_t, batch_size)\n",
    "        \n",
    "        # convert the numpy arrays batch_x and batch_t to tensor \n",
    "        # types. The PyTorch tensor type is the magic that permits \n",
    "        # automatic differentiation with respect to parameters. \n",
    "        # However, since we do not need to take the derivatives\n",
    "        # with respect to x and t, we disable this feature\n",
    "        with torch.no_grad(): # no need to compute gradients \n",
    "            # wrt. x and t\n",
    "            x = torch.from_numpy(batch_x).float()\n",
    "            t = torch.from_numpy(batch_t).float()      \n",
    "\n",
    "        # compute the output of the model for the batch of data x\n",
    "        # Note: outputs is \n",
    "        #   of shape (-1, 1), but the tensor targets, t, is\n",
    "        #   of shape (-1,)\n",
    "        # In order for the tensor operations with outputs and t\n",
    "        # to work correctly, it is necessary that they have the\n",
    "        # same shape. We can do this with the reshape method.\n",
    "        outputs = model(x).reshape(t.shape)\n",
    "   \n",
    "        # compute a noisy approximation to the average loss\n",
    "        empirical_risk = avloss(outputs, t, x)\n",
    "        \n",
    "        # use automatic differentiation to compute a \n",
    "        # noisy approximation of the local gradient\n",
    "        optimizer.zero_grad()       # clear previous gradients\n",
    "        empirical_risk.backward()   # compute gradients\n",
    "        \n",
    "        # finally, advance one step in the direction of steepest \n",
    "        # descent, using the noisy local gradient. \n",
    "        optimizer.step()            # move one step\n",
    "        \n",
    "        if ii % step == 0:\n",
    "            \n",
    "            acc_t = validate(model, avloss, train_x[:n], train_t[:n]) \n",
    "            acc_v = validate(model, avloss, valid_x[:n], valid_t[:n])\n",
    "\n",
    "            if len(xx) < 1:\n",
    "                xx.append(0)\n",
    "                print(\"%10d\\t%10.6f\\t%10.6f\" % \\\n",
    "                      (xx[-1], acc_t, acc_v))\n",
    "            else:\n",
    "                xx.append(xx[-1] + step)\n",
    "                print(\"\\r%10d\\t%10.6f\\t%10.6f\" % \\\n",
    "                      (xx[-1], acc_t, acc_v), end='')\n",
    "                \n",
    "            yy_t.append(acc_t)\n",
    "            yy_v.append(acc_v)\n",
    "    print()      \n",
    "    return (xx, yy_t, yy_v)\n",
    "\n",
    "def plot_average_loss(traces, ftsize=18):\n",
    "    \n",
    "    xx, yy_t, yy_v = traces\n",
    "    \n",
    "    # create an empty figure\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # add a subplot to it\n",
    "    nrows, ncols, index = 1,1,1\n",
    "    ax  = fig.add_subplot(nrows,ncols,index)\n",
    "\n",
    "    ax.set_title(\"Average loss\")\n",
    "    \n",
    "    ax.plot(xx, yy_t, 'b', lw=2, label='Training')\n",
    "    ax.plot(xx, yy_v, 'r', lw=2, label='Validation')\n",
    "\n",
    "    ax.set_xlabel('Iterations', fontsize=ftsize)\n",
    "    ax.set_ylabel('average loss', fontsize=ftsize)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, which=\"both\", linestyle='-')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iqnutil as ut\n",
    "importlib.reload(ut);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJC916BU-9L6"
   },
   "source": [
    "### Define model $f(\\mathbf{x}, \\theta)$\n",
    "\n",
    "For simple models, it is sufficient to use the __Sequential__ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting iqn_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile iqn_model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear( 8, 50),\n",
    "                      nn.ReLU(),\n",
    "                      \n",
    "                      nn.Linear(50, 50),\n",
    "                      nn.ReLU(),\n",
    "                      \n",
    "                      nn.Linear(50, 50),\n",
    "                      nn.ReLU(), \n",
    " \n",
    "                      nn.Linear(50, 50),\n",
    "                      nn.ReLU(), \n",
    " \n",
    "                      nn.Linear(50, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t valid-set\n",
      "         0\t  0.347823\t  0.352495\n",
      "    138920\t  0.127044\t  0.134001"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3747334/1576879949.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                   \u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                   step=traces_step)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Pulled_Github_Repositories/IQN_HEP/iqnutil.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, avloss, getbatch, train_x, train_t, valid_x, valid_t, batch_size, n_iterations, traces, step)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# to work correctly, it is necessary that they have the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# same shape. We can do this with the reshape method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# compute a noisy approximation to the average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import iqn_model as iqn\n",
    "importlib.reload(iqn)\n",
    "model = iqn.model\n",
    "print(model)\n",
    "\n",
    "n_batch       = 50\n",
    "n_iterations  = 200000\n",
    "\n",
    "learning_rate = 2.e-4\n",
    "optimizer     = torch.optim.Adam(model.parameters(), \n",
    "                                 lr=learning_rate) \n",
    "\n",
    "traces = ([], [], [])\n",
    "traces_step = 10\n",
    "\n",
    "traces = ut.train(model, optimizer, \n",
    "                  ut.average_quantile_loss,\n",
    "                  ut.get_batch,\n",
    "                  train_x, train_t, \n",
    "                  valid_x, valid_t,\n",
    "                  n_batch, \n",
    "                  n_iterations,\n",
    "                  traces,\n",
    "                  step=traces_step)\n",
    "\n",
    "ut.plot_average_loss(traces)\n",
    "\n",
    "# save model parameter dictionary\n",
    "torch.save(model.state_dict(), 'iqn_model.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration vs average loss\n",
      " iteration\t train-set\t valid-set\n",
      "    399990\t  0.126109\t  0.135942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batch       = 50\n",
    "n_iterations  = 200000\n",
    "\n",
    "traces = ut.train(model, optimizer, \n",
    "                  ut.average_quantile_loss,\n",
    "                  ut.get_batch,\n",
    "                  train_x, train_t, \n",
    "                  valid_x, valid_t,\n",
    "                  n_batch, \n",
    "                  n_iterations,\n",
    "                  traces,\n",
    "                  step=traces_step)\n",
    "\n",
    "ut.plot_average_loss(traces)\n",
    "\n",
    "# save model parameter dictionary\n",
    "torch.save(model.state_dict(), 'iqn_model400k.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = ut.ModelHandler(model, scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(df, dnn,\n",
    "               gfile='fig_model.png', \n",
    "               fgsize=(6, 6), \n",
    "               ftsize=20):\n",
    "        \n",
    "    # ----------------------------------------------\n",
    "    # histogram RecoDatapT\n",
    "    # ----------------------------------------------\n",
    "    xmin, xmax = 20, 60\n",
    "    xbins = 80\n",
    "    xstep = (xmax - xmin)/xbins\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=fgsize)\n",
    "    \n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    #ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel(r'$p_{T}$ (GeV)', fontsize=ftsize)\n",
    "\n",
    "    ax.hist(df.RecoDatapT, \n",
    "            bins=xbins, \n",
    "            range=(xmin, xmax), alpha=0.3, color='blue')\n",
    "   \n",
    "    y = dnn(df)\n",
    "    \n",
    "    ax.hist(y, \n",
    "            bins=xbins, \n",
    "            range=(xmin, xmax), \n",
    "            alpha=0.3, \n",
    "            color='red')\n",
    "    ax.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(gfile)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(test_data, dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DRL_19_REINFORCE_Algorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
