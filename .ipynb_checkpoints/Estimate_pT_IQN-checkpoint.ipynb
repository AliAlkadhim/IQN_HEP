{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bdc1f538-b5de-4211-8a45-b2dcffb52552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# the standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# the standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# the standard modules for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard scientific python module\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.optimize as op\n",
    "\n",
    "# standard symbolic algebra module\n",
    "#import sympy as sm\n",
    "#sm.init_printing()\n",
    "\n",
    "# module to save results\n",
    "import joblib as jb\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "# split data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# linearly transform a feature to zero mean and unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to reload modules\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# update fonts\n",
    "FONTSIZE = 18\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "\n",
    "# set usetex = False if LaTex is not \n",
    "# available on your system or if the \n",
    "# rendering is too slow\n",
    "mp.rc('text', usetex=True)\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "#seed = 128\n",
    "#rnd  = np.random.RandomState(seed)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aaf71fd9-26e5-42f9-b81d-d4d5f469f317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rawRecoDatapT</th>\n",
       "      <th>rawRecoDataeta</th>\n",
       "      <th>rawRecoDataphi</th>\n",
       "      <th>rawRecoDatam</th>\n",
       "      <th>RecoDatapT</th>\n",
       "      <th>RecoDataeta</th>\n",
       "      <th>RecoDataphi</th>\n",
       "      <th>RecoDatam</th>\n",
       "      <th>genDatapT</th>\n",
       "      <th>genDataeta</th>\n",
       "      <th>genDataphi</th>\n",
       "      <th>genDatam</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0586</td>\n",
       "      <td>3.511970</td>\n",
       "      <td>1.503010</td>\n",
       "      <td>5.69919</td>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>45.4608</td>\n",
       "      <td>3.379820</td>\n",
       "      <td>1.470130</td>\n",
       "      <td>13.24440</td>\n",
       "      <td>0.536525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47.9465</td>\n",
       "      <td>0.776638</td>\n",
       "      <td>-1.251970</td>\n",
       "      <td>6.72517</td>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>56.2643</td>\n",
       "      <td>0.811412</td>\n",
       "      <td>-1.324120</td>\n",
       "      <td>10.55060</td>\n",
       "      <td>0.130536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29.5200</td>\n",
       "      <td>-1.084730</td>\n",
       "      <td>1.834230</td>\n",
       "      <td>4.06446</td>\n",
       "      <td>29.3586</td>\n",
       "      <td>-1.17862</td>\n",
       "      <td>1.84039</td>\n",
       "      <td>9.95503</td>\n",
       "      <td>34.6377</td>\n",
       "      <td>-1.131020</td>\n",
       "      <td>1.801820</td>\n",
       "      <td>7.65844</td>\n",
       "      <td>0.500162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23.2719</td>\n",
       "      <td>-2.822960</td>\n",
       "      <td>0.216718</td>\n",
       "      <td>3.50878</td>\n",
       "      <td>20.9593</td>\n",
       "      <td>2.13374</td>\n",
       "      <td>-2.86886</td>\n",
       "      <td>9.55921</td>\n",
       "      <td>27.4120</td>\n",
       "      <td>-2.842550</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>5.18675</td>\n",
       "      <td>0.490624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.4644</td>\n",
       "      <td>2.985000</td>\n",
       "      <td>1.306930</td>\n",
       "      <td>4.11101</td>\n",
       "      <td>35.2909</td>\n",
       "      <td>2.96499</td>\n",
       "      <td>1.36464</td>\n",
       "      <td>10.69580</td>\n",
       "      <td>30.3263</td>\n",
       "      <td>3.040300</td>\n",
       "      <td>1.341270</td>\n",
       "      <td>5.74890</td>\n",
       "      <td>0.417064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rawRecoDatapT  rawRecoDataeta  rawRecoDataphi  rawRecoDatam  \\\n",
       "0           0        29.0586        3.511970        1.503010       5.69919   \n",
       "1           1        47.9465        0.776638       -1.251970       6.72517   \n",
       "2           2        29.5200       -1.084730        1.834230       4.06446   \n",
       "3           3        23.2719       -2.822960        0.216718       3.50878   \n",
       "4           4        30.4644        2.985000        1.306930       4.11101   \n",
       "\n",
       "   RecoDatapT  RecoDataeta  RecoDataphi  RecoDatam  genDatapT  genDataeta  \\\n",
       "0     40.3892      3.41479      1.47023   12.53740    45.4608    3.379820   \n",
       "1     40.3892      3.41479      1.47023   12.53740    56.2643    0.811412   \n",
       "2     29.3586     -1.17862      1.84039    9.95503    34.6377   -1.131020   \n",
       "3     20.9593      2.13374     -2.86886    9.55921    27.4120   -2.842550   \n",
       "4     35.2909      2.96499      1.36464   10.69580    30.3263    3.040300   \n",
       "\n",
       "   genDataphi  genDatam       tau  \n",
       "0    1.470130  13.24440  0.536525  \n",
       "1   -1.324120  10.55060  0.130536  \n",
       "2    1.801820   7.65844  0.500162  \n",
       "3    0.345529   5.18675  0.490624  \n",
       "4    1.341270   5.74890  0.417064  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4a2e6ff8-1552-4ff9-aa0e-0cb31a6dacc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecoDatapT</th>\n",
       "      <th>RecoDataeta</th>\n",
       "      <th>RecoDataphi</th>\n",
       "      <th>RecoDatam</th>\n",
       "      <th>genDatapT</th>\n",
       "      <th>genDataeta</th>\n",
       "      <th>genDataphi</th>\n",
       "      <th>genDatam</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>45.4608</td>\n",
       "      <td>3.379820</td>\n",
       "      <td>1.470130</td>\n",
       "      <td>13.24440</td>\n",
       "      <td>0.536525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.3892</td>\n",
       "      <td>3.41479</td>\n",
       "      <td>1.47023</td>\n",
       "      <td>12.53740</td>\n",
       "      <td>56.2643</td>\n",
       "      <td>0.811412</td>\n",
       "      <td>-1.324120</td>\n",
       "      <td>10.55060</td>\n",
       "      <td>0.130536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.3586</td>\n",
       "      <td>-1.17862</td>\n",
       "      <td>1.84039</td>\n",
       "      <td>9.95503</td>\n",
       "      <td>34.6377</td>\n",
       "      <td>-1.131020</td>\n",
       "      <td>1.801820</td>\n",
       "      <td>7.65844</td>\n",
       "      <td>0.500162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.9593</td>\n",
       "      <td>2.13374</td>\n",
       "      <td>-2.86886</td>\n",
       "      <td>9.55921</td>\n",
       "      <td>27.4120</td>\n",
       "      <td>-2.842550</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>5.18675</td>\n",
       "      <td>0.490624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.2909</td>\n",
       "      <td>2.96499</td>\n",
       "      <td>1.36464</td>\n",
       "      <td>10.69580</td>\n",
       "      <td>30.3263</td>\n",
       "      <td>3.040300</td>\n",
       "      <td>1.341270</td>\n",
       "      <td>5.74890</td>\n",
       "      <td>0.417064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecoDatapT  RecoDataeta  RecoDataphi  RecoDatam  genDatapT  genDataeta  \\\n",
       "0     40.3892      3.41479      1.47023   12.53740    45.4608    3.379820   \n",
       "1     40.3892      3.41479      1.47023   12.53740    56.2643    0.811412   \n",
       "2     29.3586     -1.17862      1.84039    9.95503    34.6377   -1.131020   \n",
       "3     20.9593      2.13374     -2.86886    9.55921    27.4120   -2.842550   \n",
       "4     35.2909      2.96499      1.36464   10.69580    30.3263    3.040300   \n",
       "\n",
       "   genDataphi  genDatam       tau  \n",
       "0    1.470130  13.24440  0.536525  \n",
       "1   -1.324120  10.55060  0.130536  \n",
       "2    1.801820   7.65844  0.500162  \n",
       "3    0.345529   5.18675  0.490624  \n",
       "4    1.341270   5.74890  0.417064  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,5:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d28b26ef-0109-4c4b-a53c-d62d24f8dc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.41479   ,  1.47023   , 12.5374    , ...,  1.47013   ,\n",
       "        13.2444    ,  0.53652539],\n",
       "       [ 3.41479   ,  1.47023   , 12.5374    , ..., -1.32412   ,\n",
       "        10.5506    ,  0.13053623],\n",
       "       [-1.17862   ,  1.84039   ,  9.95503   , ...,  1.80182   ,\n",
       "         7.65844   ,  0.50016227],\n",
       "       ...,\n",
       "       [-1.49005   , -1.42238   , 11.155     , ...,  1.85921   ,\n",
       "         8.8265    ,  0.11958587],\n",
       "       [-0.654844  , -1.26413   ,  3.893     , ..., -1.21499   ,\n",
       "         4.87261   ,  0.5541255 ],\n",
       "       [-1.10686   ,  1.3181    ,  6.0953    , ...,  1.33004   ,\n",
       "         3.94825   ,  0.05202467]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = ['genData', 'RecoData']\n",
    "kinematics=['pT','eta','phi','m']\n",
    "targets = kinematics#for reco level, but same names\n",
    "Networks = ['RecoNN', 'genNN']\n",
    "\n",
    "target = df['RecoDatapT'].to_numpy()\n",
    "data =  df.drop('RecoDatapT', axis=1).to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e16158f-8207-4190-bb15-59784d3a5e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.3892, 40.3892, 29.3586, ..., 27.0034, 23.8815, 33.2208])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f3b3a95d-3bf3-4b7d-bf34-8c9a95ab2270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape (80000, 1)\n",
      "input data shape (100000, 8)\n"
     ]
    }
   ],
   "source": [
    "# train_targets = train_targets.reshape(-1,1)\n",
    "# test_targets = test_targets.reshape(-1,1)\n",
    "\n",
    "print('target shape', train_targets.shape)\n",
    "print('input data shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "610a3400-3651-4125-8256-e5ab5f48b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntargets = 1\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dafd1bfd-b236-45a2-aa29-810cb7966bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape =  (80000, 8) \n",
      "\n",
      "test_data shape =  (20000, 8) \n",
      "\n",
      "train_targets shape =  (80000, 1) \n",
      "\n",
      "test_targets shape =  (20000, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_targets = train_targets.reshape(-1,1)\n",
    "test_targets = test_targets.reshape(-1,1)\n",
    "\n",
    "sets= [train_data, test_data, train_targets, test_targets]\n",
    "set_names = ['train_data', 'test_data', 'train_targets', 'test_targets']\n",
    "# vnames = [name for name in globals() if globals()[name] is variable]\n",
    "\n",
    "def variable_string(variable):\n",
    "    return [k for k, v in locals().items() if v == variable][0]\n",
    "\n",
    "for var_name, var in zip(set_names, sets):\n",
    "    print(var_name \n",
    "          + ' shape = ', var.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "68142b60-eb97-4866-94f6-3d90a25782ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = StandardScaler()#this is always recommended for logistic regression\n",
    "# train_data= sc.fit_transform(train_data)\n",
    "# test_data = sc.transform(test_data)\n",
    "# train_data.mean(), (train_data.std())**2#check to make sure mean=0, std=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1e3547fd-700a-4b2d-b1c9-7cf8c0297b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([ 3.9172e+00, -1.6980e+00,  5.8360e+00,  3.2731e+01, -3.0877e-02,\n",
      "         1.7757e+00,  6.8790e+00,  4.9855e-01]), 'y': tensor([30.9906])} <__main__.CustomDataset object at 0x7fdb7143bb90>\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset:\n",
    "    \"\"\"This takes the index for the data and target and gives dictionary of tensors of data and targets.\n",
    "    For example we could do train_dataset = CustomDataset(train_data, train_targets); test_dataset = CustomDataset(test_data, test_targets)\n",
    " where train and test_dataset are np arrays that are reshaped to (-1,1).\n",
    " Then train_dataset[0] gives a dictionary of samples \"X\" and targets\"\"\"\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets=targets\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        current_sample = self.data[idx, :]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\"x\": torch.tensor(current_sample, dtype = torch.float),\n",
    "               \"y\": torch.tensor(current_target, dtype= torch.float),\n",
    "               }#this already makes the targets made of one tensor (of one value) each\n",
    "    \n",
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)\n",
    "print(train_dataset[0], train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f1b8c07a-a637-4f2b-8bc9-0c0184174e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=2, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d6071393-9cc1-4735-8c2a-4e798d630b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mymodels import RegressionModel\n",
    "class RegressionModel(nn.Module):\n",
    "    #inherit from the super class\n",
    "    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            if len(layers) ==0:\n",
    "                #inital layer has to have size of input features as its input layer\n",
    "                #its output layer can have any size but it must match the size of the input layer of the next linear layer\n",
    "                #here we choose its output layer as the hidden size (fully connected)\n",
    "                layers.append(nn.Linear(nfeatures, hidden_size))\n",
    "                #batch normalization\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                #ReLU activation \n",
    "                layers.append(nn.ReLU())\n",
    "            else:\n",
    "                #if this is not the first layer (we dont have layers)\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                layers.append(nn.ReLU())\n",
    "                #output layer:\n",
    "        layers.append(nn.Linear(hidden_size, ntargets)) \n",
    "        \n",
    "        layers.append(nn.Sigmoid())\n",
    "            #we have defined sequential model using the layers in oulist \n",
    "        self.model = nn.Sequential(*layers)\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "89e96587-d19a-4e3d-ae85-65f73f17a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape =  (80000, 8)\n"
     ]
    }
   ],
   "source": [
    "# n_examples, n_inputs = train_data.shape\n",
    "# n_outputs, n_hidden = 1, 16\n",
    "print('train_data.shape = ',train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "876d298d-2338-4843-beda-352a5d045eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.3, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.3, inplace=False)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (17): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Dropout(p=0.3, inplace=False)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (21): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): Dropout(p=0.3, inplace=False)\n",
      "    (23): ReLU()\n",
      "    (24): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (25): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): Dropout(p=0.3, inplace=False)\n",
      "    (27): ReLU()\n",
      "    (28): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (29): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): Dropout(p=0.3, inplace=False)\n",
      "    (31): ReLU()\n",
      "    (32): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (33): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model =  RegressionModel(nfeatures=train_data.shape[1], \n",
    "               ntargets=1,\n",
    "               nlayers=8, \n",
    "               hidden_size=16, \n",
    "               dropout=0.3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8a5d5858-3b3e-4788-85eb-8146b6837564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %writefile training/RegressionEngine.py\n",
    "class RegressionEngine:\n",
    "    \"\"\"loss, training and evaluation\"\"\"\n",
    "    def __init__(self, model, optimizer):\n",
    "                 #, device):\n",
    "        self.model = model\n",
    "        #self.device= device\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    #the loss function returns the loss function. It is a static method so it doesn't need self\n",
    "    @staticmethod\n",
    "    def quadratic_loss(targets, outputs):\n",
    "         return nn.MSELoss()(outputs, targets)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_quadratic_loss(targets, outputs):\n",
    "    # f and t must be of the same shape\n",
    "        return  torch.mean((outputs - targets)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_absolute_error(targets, outputs):\n",
    "    # f and t must be of the same shape\n",
    "        return  torch.mean(abs(outputs - targets))\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def average_cross_entropy_loss(targets, outputs):\n",
    "        # f and t must be of the same shape\n",
    "        loss = torch.where(targets > 0.5, torch.log(outputs), torch.log(1 - outputs))\n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_quantile_loss(targets, outputs):\n",
    "        # f and t must be of the same shape\n",
    "        tau = torch.rand(outputs.shape)\n",
    "        return torch.mean(torch.where(targets >= outputs, \n",
    "                                      tau * abs(targets - outputs), \n",
    "                                      (1 - tau)*abs(outputs - targets)))\n",
    "\n",
    "    def train(self, data_loader):\n",
    "        \"\"\"the training function: takes the training dataloader\"\"\"\n",
    "        self.model.train()\n",
    "        final_loss = 0\n",
    "        for data in data_loader:\n",
    "            self.optimizer.zero_grad()#only optimize weights for the current batch, otherwise it's meaningless!\n",
    "            inputs = data[\"x\"]\n",
    "            targets = data[\"y\"]\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.average_quantile_loss(targets, outputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            final_loss += loss.item()\n",
    "            return final_loss / len(data_loader)\n",
    "\n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"the training function: takes the training dataloader\"\"\"\n",
    "        self.model.eval()\n",
    "        final_loss = 0\n",
    "        for data in data_loader:\n",
    "            inputs = data[\"x\"]#.to(self.device)\n",
    "            targets = data[\"y\"]#.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.average_quantile_loss(targets, outputs)\n",
    "            final_loss += loss.item()\n",
    "            return outputs.flatten()\n",
    "            #return final_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0c8240b6-104c-4260-8da2-0a3c4393b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, engine, early_stopping_iter, epochs):\n",
    "    train_losses, test_losses = [], []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "    eng = RegressionEngine(model=model, optimizer = optimizer)\n",
    "    best_loss = np.inf\n",
    "    early_stopping_iter = 10\n",
    "    early_stopping_counter = 0\n",
    "    # EPOCHS=22\n",
    "    EPOCHS=epochs\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = eng.train(train_loader)\n",
    "        test_loss = eng.train(test_loader)\n",
    "        print(\"Epoch : %-10g, Training Loss: %-10g, Test Loss: %-10g\" % (epoch, train_loss, test_loss))\n",
    "        #print(f\"{epoch}, {train_loss}, {test_loss}\")\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter > early_stopping_iter:\n",
    "            #if we are not improving for 10 iterations then break the loop\n",
    "            #we could save best model here\n",
    "            break\n",
    "    \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    train_losses=np.array(train_losses); test_losses=np.array(test_losses)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # add a subplot to it\n",
    "    nrows, ncols, index = 1,1,1\n",
    "    ax  = fig.add_subplot(nrows,ncols,index)\n",
    "    ax.set_title(\"Average loss\")\n",
    "    \n",
    "    epoch_list = np.arange(1, train_losses.shape[0]+1)\n",
    "    ax.plot(epoch_list, train_losses, label = 'Train')\n",
    "    ax.plot(epoch_list, test_losses, label='Test')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(loc='upper right')\n",
    "    return train_losses, test_losses\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f97be35-ab2c-4f0f-b82f-c32df5050768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0         , Training Loss: 0.000917102, Test Loss: 0.00336703\n",
      "Epoch : 1         , Training Loss: 0.000687194, Test Loss: 0.002986  \n",
      "Epoch : 2         , Training Loss: 0.000793731, Test Loss: 0.00280183\n",
      "Epoch : 3         , Training Loss: 0.00077007, Test Loss: 0.0040017 \n",
      "Epoch : 4         , Training Loss: 0.00120342, Test Loss: 0.00182377\n",
      "Epoch : 5         , Training Loss: 0.00110623, Test Loss: 0.00355007\n",
      "Epoch : 6         , Training Loss: 0.000562496, Test Loss: 0.00248925\n",
      "Epoch : 7         , Training Loss: 0.000315926, Test Loss: 0.00356588\n",
      "Epoch : 8         , Training Loss: 0.00034049, Test Loss: 0.00369664\n",
      "Epoch : 9         , Training Loss: 0.000825061, Test Loss: 0.00336824\n",
      "Epoch : 10        , Training Loss: 0.000902389, Test Loss: 0.00191493\n",
      "Epoch : 11        , Training Loss: 0.00147708, Test Loss: 0.00281912\n",
      "Epoch : 12        , Training Loss: 0.000969893, Test Loss: 0.00371876\n",
      "Epoch : 13        , Training Loss: 0.000895869, Test Loss: 0.00453343\n",
      "Epoch : 14        , Training Loss: 0.000869983, Test Loss: 0.00312788\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "train_losses, test_losses=train(optimizer, \n",
    "      engine =RegressionEngine(model=model, optimizer = optimizer),\n",
    "      early_stopping_iter = 100,\n",
    "      epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "72f552c7-56b9-4059-8608-3459d65c5144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14,), (14,))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_losses).shape, np.array(test_losses).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "01c3cac7-20aa-46b8-ace9-031b77cb41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(1, train_losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fce7cc65-2266-4098-b5fc-8950a02b4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    accuracies = []\n",
    "\n",
    "    #evaluate\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data_cp = copy.deepcopy(data)\n",
    "\n",
    "            xtest = data_cp[\"x\"]\n",
    "            ytest = data_cp[\"y\"]#y is Z values. I could add here my computed p-value for each theta,\n",
    "            #and make a dataframe col1:theta, col2: Z, col3, phat, col4: computedp-value\n",
    "            output = model(xtest)\n",
    "            labels.append(ytest)\n",
    "            outputs.append(output)\n",
    "\n",
    "            y_predicted_cls = output.round()\n",
    "            acc = y_predicted_cls.eq(ytest).sum() / float(ytest.shape[0])# number of correct predictions/sizeofytest\n",
    "            #accuracies.append(acc.numpy())\n",
    "            #print(f'accuracy: {acc.item():.4f}')\n",
    "\n",
    "            del data_cp\n",
    "\n",
    "    #     acc = y_predicted_cls.eq(ytest).sum() / float(ytest.shape[0])\n",
    "    #     print(f'accuracy: {acc.item():.4f}')\n",
    "            \n",
    "    OUTPUTS = torch.cat(outputs).view(-1).numpy()\n",
    "\n",
    "    LABELS = torch.cat(labels).view(-1).numpy()\n",
    "    print('outputs of model: ', OUTPUTS)\n",
    "    print('\\nactual labels (targets Z): ', LABELS)\n",
    "    return OUTPUTS.flatten(), LABELS.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "466955c7-7ca7-4272-8789-9c1a53b2f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs of model:  [0.99262035 0.92160416 0.9969234  ... 0.9497656  0.98724824 0.96784693]\n",
      "\n",
      "actual labels (targets Z):  [28.2491 28.3123 28.2231 ... 20.7069 24.4039 29.9623]\n"
     ]
    }
   ],
   "source": [
    "OUTPUTS, LABELS = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "01ec1c3d-6b82-4f0f-b5cc-b464d00c4638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.8277e+04, 1.4950e+03, 1.8000e+02, 3.3000e+01, 6.0000e+00,\n",
       "        3.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([ 20.0008  ,  37.75662 ,  55.51244 ,  73.268265,  91.02408 ,\n",
       "        108.7799  , 126.53572 , 144.29155 , 162.04736 , 179.80319 ,\n",
       "        197.559   ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad4498-9888-4707-a7d5-504ac1c4dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_phat_from_regressor(model, test_data):\n",
    "    X_torch = torch.from_numpy(X).float()\n",
    "    X_torch= Tensor(X_torch)\n",
    "    model.eval()\n",
    "    phat = model(X_torch)\n",
    "    phat = phat.squeeze()\n",
    "    phat=phat.detach().numpy().flatten()#detaches it from the computational history/prevent future computations from being tracked\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
